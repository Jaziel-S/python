# pip install torch pandas matplotlib scikit-learn mplcursors

import torch
import torch.nn as nn
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import numpy as np
import mplcursors

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆé˜²æ­¢ä¹±ç ï¼‰
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# è¯»å– CSV æ•°æ®
data = pd.read_csv('data.csv')  # ç¡®ä¿æ–‡ä»¶ä¸­æœ‰ 'x' å’Œ 'y' ä¸¤åˆ—
x_raw = data[['x']].values
y_raw = data[['y']].values

# æ•°æ®æ ‡å‡†åŒ–ï¼ˆé¿å…å°ºåº¦ä¸ä¸€è‡´ï¼‰
scaler_x = StandardScaler()
scaler_y = StandardScaler()
x = torch.tensor(scaler_x.fit_transform(x_raw), dtype=torch.float32)
y = torch.tensor(scaler_y.fit_transform(y_raw), dtype=torch.float32)

# å®šä¹‰ç¥ç»ç½‘ç»œç»“æ„
class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(1, 64),
            nn.Tanh(),
            nn.Linear(64, 64),
            nn.Tanh(),
            nn.Linear(64, 1)
        )

    def forward(self, x):
        return self.net(x)

model = Net()
loss_fn = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# è®­ç»ƒç½‘ç»œ
loss_history = []
# è®¾ç½®æ—©åœå‚æ•°
patience = 500  # å®¹å¿å‘¨æœŸï¼ˆä¾‹å¦‚è¿ç»­500è½®æ— æ˜æ˜¾æ”¹å–„ï¼‰
min_delta = 1e-6  # æœ€å°æ”¹å–„å¹…åº¦
best_loss = float('inf')
trigger_times = 0

for epoch in range(5000):
    y_pred = model(x)
    loss = loss_fn(y_pred, y)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    loss_value = loss.item()
    loss_history.append(loss_value)

    # æ‰“å°
    if epoch % 500 == 0:
        print(f"Epoch {epoch}, Loss: {loss_value:.6f}")

    # æ—©åœåˆ¤æ–­
    if best_loss - loss_value > min_delta:
        best_loss = loss_value
        trigger_times = 0
    else:
        trigger_times += 1
        if trigger_times >= patience:
            print(f"ğŸ“‰ Lossåœ¨ {patience} è½®å†…æ— æ˜¾è‘—æ”¹å–„ï¼Œæå‰åœæ­¢è®­ç»ƒäº Epoch {epoch}")
            break

# ç”¨è®­ç»ƒé›† x é¢„æµ‹å¹¶åå½’ä¸€åŒ–
y_pred_scaled_train = model(x).detach().numpy()
y_pred_train = scaler_y.inverse_transform(y_pred_scaled_train)
y_true = y_raw

# æ­£ç¡®è®¡ç®— RÂ²
r2 = 1 - np.sum((y_true - y_pred_train)**2) / np.sum((y_true - np.mean(y_true))**2)

# ç”Ÿæˆæ‹Ÿåˆæ›²çº¿ç”¨äºç»˜å›¾ï¼Œå¦‚æœå¸Œæœ›é€‰ç‚¹æ›´ç²¾ç»†ï¼Œå¯ä»¥æŠŠ x_plot çš„é‡‡æ ·å¯†åº¦æé«˜
x_plot = torch.linspace(x.min(), x.max(), 200).reshape(-1, 1)
y_plot_scaled = model(x_plot).detach().numpy()
x_plot_orig = scaler_x.inverse_transform(x_plot.numpy())
y_plot_orig = scaler_y.inverse_transform(y_plot_scaled)

# ç»˜å›¾
fig, ax = plt.subplots(figsize=(8, 5))
ax.scatter(x_raw, y_raw, color='black', s=10, label='åŸå§‹æ•°æ®')
line, = ax.plot(x_plot_orig, y_plot_orig, color='red', label=f'ç¥ç»ç½‘ç»œæ‹Ÿåˆ (RÂ²={r2:.4f})')

# æ·»åŠ é¼ æ ‡é€‰ç‚¹åŠŸèƒ½ï¼ˆåªä½œç”¨äºæ‹Ÿåˆæ›²çº¿ï¼‰
cursor = mplcursors.cursor(line, hover=True)
cursor.connect("add", lambda sel: sel.annotation.set_text(
    f"x={sel.target[0]:.3f}\ny={sel.target[1]:.3f}"))

ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_title('æ‹Ÿåˆæ›²çº¿mplcursors')
ax.grid(True)
ax.legend()
plt.tight_layout()
plt.savefig('nn_fit.png')  # å¯é€‰ï¼šä¿å­˜å›¾åƒ

# ç»˜åˆ¶lossæ›²çº¿ï¼ŒæŸ¥çœ‹æ˜¯å¦æ”¶æ•›
plt.figure(figsize=(8, 4))
plt.plot(loss_history, color='blue')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('è®­ç»ƒè¿‡ç¨‹ä¸­çš„lossæ›²çº¿')
plt.grid(True)
plt.tight_layout()
plt.show()

# ğŸ“¢ æç¤ºç”¨æˆ·æ˜¯å¦ä¿å­˜æ‹Ÿåˆç»“æœ
choice = input("æ˜¯å¦ä¿å­˜æ‹Ÿåˆæ›²çº¿ç‚¹é›†ä¸º CSVï¼Ÿè¾“å…¥ y ä¿å­˜ï¼Œè¾“å…¥ n è·³è¿‡ï¼š").strip().lower()

if choice == 'y':
    pd.DataFrame({
        'x': x_plot_orig.flatten(),
        'y': y_plot_orig.flatten()
    }).to_csv('nn_fit_curve.csv', index=False)
    print("âœ… æ‹Ÿåˆæ›²çº¿å·²ä¿å­˜ä¸º nn_fit_curve.csv")
elif choice == 'n':
    print("â­ï¸ å·²è·³è¿‡ä¿å­˜")
else:
    print("âš ï¸ æ— æ•ˆè¾“å…¥ï¼Œæœªä¿å­˜ä»»ä½•å†…å®¹")
